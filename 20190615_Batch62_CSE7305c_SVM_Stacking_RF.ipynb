{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Reading and Pre-Processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attribute information:**\n",
    "\n",
    "1. **target**: DIE (1), LIVE (2)\n",
    "2. **age**: 10, 20, 30, 40, 50, 60, 70, 80\n",
    "3. **gender**: male (1), female (2)\n",
    "\n",
    "           ------ no = 0,   yes = 1 ------\n",
    "\n",
    "4. **steroid**: no, yes \n",
    "5. **antivirals**: no, yes \n",
    "6. **fatique**: no, yes \n",
    "7. **malaise**: no, yes \n",
    "8. **anorexia**: no, yes \n",
    "9. **liverBig**: no, yes \n",
    "10. **liverFirm**: no, yes \n",
    "11. **spleen**: no, yes \n",
    "12. **spiders**: no, yes\n",
    "13. **ascites**: no, yes \n",
    "14. **varices**: no, yes\n",
    "15. **histology**: no, yes\n",
    "\n",
    "\n",
    "16. **bilirubin**: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00 -- \n",
    "17. **alk**: 33, 80, 120, 160, 200, 250 ---\n",
    "18. **sgot**: 13, 100, 200, 300, 400, 500, ---\n",
    "19. **albu**: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0, --- \n",
    "20. **protime**: 10, 20, 30, 40, 50, 60, 70, 80, 90, --- \n",
    "\n",
    "        NA's are represented with \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Read the HEPATITIS dataset and check the data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read \"hepatitis.csv\" using pandas\n",
    "# target =  1: Die; 2: Live \n",
    "data = pd.read_csv(\"hepatitis.csv\", na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liverBig</th>\n",
       "      <th>...</th>\n",
       "      <th>spleen</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bili</th>\n",
       "      <th>alk</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albu</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target  age  gender  steroid  antivirals  fatigue  malaise  anorexia  \\\n",
       "0   1       2   30       2      1.0           2      2.0      2.0       2.0   \n",
       "1   2       2   50       1      1.0           2      1.0      2.0       2.0   \n",
       "2   3       2   78       1      2.0           2      1.0      2.0       2.0   \n",
       "3   4       2   31       1      NaN           1      2.0      2.0       2.0   \n",
       "4   5       2   34       1      2.0           2      2.0      2.0       2.0   \n",
       "\n",
       "   liverBig    ...      spleen  spiders  ascites  varices  bili    alk   sgot  \\\n",
       "0       1.0    ...         2.0      2.0      2.0      2.0   1.0   85.0   18.0   \n",
       "1       1.0    ...         2.0      2.0      2.0      2.0   0.9  135.0   42.0   \n",
       "2       2.0    ...         2.0      2.0      2.0      2.0   0.7   96.0   32.0   \n",
       "3       2.0    ...         2.0      2.0      2.0      2.0   0.7   46.0   52.0   \n",
       "4       2.0    ...         2.0      2.0      2.0      2.0   1.0    NaN  200.0   \n",
       "\n",
       "   albu  protime  histology  \n",
       "0   4.0      NaN          1  \n",
       "1   3.5      NaN          1  \n",
       "2   4.0      NaN          1  \n",
       "3   4.0     80.0          1  \n",
       "4   4.0      NaN          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Check basic summary statistics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liverBig</th>\n",
       "      <th>...</th>\n",
       "      <th>spleen</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bili</th>\n",
       "      <th>alk</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albu</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>151.00000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.793548</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>1.103226</td>\n",
       "      <td>1.506494</td>\n",
       "      <td>1.845161</td>\n",
       "      <td>1.350649</td>\n",
       "      <td>1.603896</td>\n",
       "      <td>1.792208</td>\n",
       "      <td>1.827586</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.88000</td>\n",
       "      <td>1.427517</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>85.89404</td>\n",
       "      <td>3.817266</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>1.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.888751</td>\n",
       "      <td>0.406070</td>\n",
       "      <td>12.565878</td>\n",
       "      <td>0.305240</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.362923</td>\n",
       "      <td>0.478730</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.379049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40134</td>\n",
       "      <td>0.475296</td>\n",
       "      <td>0.341073</td>\n",
       "      <td>0.32605</td>\n",
       "      <td>1.212149</td>\n",
       "      <td>51.508109</td>\n",
       "      <td>89.65089</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>22.875244</td>\n",
       "      <td>0.499266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>74.250000</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>58.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>116.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>100.50000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>648.00000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      target         age      gender     steroid  antivirals  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  154.000000  155.000000   \n",
       "mean    78.000000    1.793548   41.200000    1.103226    1.506494    1.845161   \n",
       "std     44.888751    0.406070   12.565878    0.305240    0.501589    0.362923   \n",
       "min      1.000000    1.000000    7.000000    1.000000    1.000000    1.000000   \n",
       "25%     39.500000    2.000000   32.000000    1.000000    1.000000    2.000000   \n",
       "50%     78.000000    2.000000   39.000000    1.000000    2.000000    2.000000   \n",
       "75%    116.500000    2.000000   50.000000    1.000000    2.000000    2.000000   \n",
       "max    155.000000    2.000000   78.000000    2.000000    2.000000    2.000000   \n",
       "\n",
       "          fatigue     malaise    anorexia    liverBig     ...         spleen  \\\n",
       "count  154.000000  154.000000  154.000000  145.000000     ...      150.00000   \n",
       "mean     1.350649    1.603896    1.792208    1.827586     ...        1.80000   \n",
       "std      0.478730    0.490682    0.407051    0.379049     ...        0.40134   \n",
       "min      1.000000    1.000000    1.000000    1.000000     ...        1.00000   \n",
       "25%      1.000000    1.000000    2.000000    2.000000     ...        2.00000   \n",
       "50%      1.000000    2.000000    2.000000    2.000000     ...        2.00000   \n",
       "75%      2.000000    2.000000    2.000000    2.000000     ...        2.00000   \n",
       "max      2.000000    2.000000    2.000000    2.000000     ...        2.00000   \n",
       "\n",
       "          spiders     ascites    varices        bili         alk       sgot  \\\n",
       "count  150.000000  150.000000  150.00000  149.000000  126.000000  151.00000   \n",
       "mean     1.660000    1.866667    1.88000    1.427517  105.325397   85.89404   \n",
       "std      0.475296    0.341073    0.32605    1.212149   51.508109   89.65089   \n",
       "min      1.000000    1.000000    1.00000    0.300000   26.000000   14.00000   \n",
       "25%      1.000000    2.000000    2.00000    0.700000   74.250000   31.50000   \n",
       "50%      2.000000    2.000000    2.00000    1.000000   85.000000   58.00000   \n",
       "75%      2.000000    2.000000    2.00000    1.500000  132.250000  100.50000   \n",
       "max      2.000000    2.000000    2.00000    8.000000  295.000000  648.00000   \n",
       "\n",
       "             albu     protime   histology  \n",
       "count  139.000000   88.000000  155.000000  \n",
       "mean     3.817266   61.852273    1.451613  \n",
       "std      0.651523   22.875244    0.499266  \n",
       "min      2.100000    0.000000    1.000000  \n",
       "25%      3.400000   46.000000    1.000000  \n",
       "50%      4.000000   61.000000    1.000000  \n",
       "75%      4.200000   76.250000    2.000000  \n",
       "max      6.400000  100.000000    2.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Check for value counts in target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79.354839\n",
       "1    20.645161\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['target'].value_counts()/data['target'].count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check the datatype of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              int64\n",
       "target          int64\n",
       "age             int64\n",
       "gender          int64\n",
       "steroid       float64\n",
       "antivirals      int64\n",
       "fatigue       float64\n",
       "malaise       float64\n",
       "anorexia      float64\n",
       "liverBig      float64\n",
       "liverFirm     float64\n",
       "spleen        float64\n",
       "spiders       float64\n",
       "ascites       float64\n",
       "varices       float64\n",
       "bili          float64\n",
       "alk           float64\n",
       "sgot          float64\n",
       "albu          float64\n",
       "protime       float64\n",
       "histology       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Drop columns which are not significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"ID\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'age', 'gender', 'steroid', 'antivirals', 'fatigue',\n",
       "       'malaise', 'anorexia', 'liverBig', 'liverFirm', 'spleen', 'spiders',\n",
       "       'ascites', 'varices', 'bili', 'alk', 'sgot', 'albu', 'protime',\n",
       "       'histology'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Identify the Categorical Columns and store them in a variable cat_cols and numerical into num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"age\", \"bili\", \"alk\", \"sgot\", \"albu\", \"protime\"]\n",
    "cat_cols = ['gender', 'steroid', 'antivirals', 'fatigue', 'malaise', 'anorexia', 'liverBig', \n",
    "            'liverFirm', 'spleen', 'spiders', 'ascites', 'varices', 'histology']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Checking the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target         0\n",
       "age            0\n",
       "gender         0\n",
       "steroid        1\n",
       "antivirals     0\n",
       "fatigue        1\n",
       "malaise        1\n",
       "anorexia       1\n",
       "liverBig      10\n",
       "liverFirm     11\n",
       "spleen         5\n",
       "spiders        5\n",
       "ascites        5\n",
       "varices        5\n",
       "bili           6\n",
       "alk           29\n",
       "sgot           4\n",
       "albu          16\n",
       "protime       67\n",
       "histology      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "#data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liverBig</th>\n",
       "      <th>liverFirm</th>\n",
       "      <th>spleen</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bili</th>\n",
       "      <th>alk</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albu</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  age  gender  steroid  antivirals  fatigue  malaise  anorexia  \\\n",
       "0       2   30       2      1.0           2      2.0      2.0       2.0   \n",
       "1       2   50       1      1.0           2      1.0      2.0       2.0   \n",
       "2       2   78       1      2.0           2      1.0      2.0       2.0   \n",
       "3       2   31       1      NaN           1      2.0      2.0       2.0   \n",
       "4       2   34       1      2.0           2      2.0      2.0       2.0   \n",
       "\n",
       "   liverBig  liverFirm  spleen  spiders  ascites  varices  bili    alk   sgot  \\\n",
       "0       1.0        2.0     2.0      2.0      2.0      2.0   1.0   85.0   18.0   \n",
       "1       1.0        2.0     2.0      2.0      2.0      2.0   0.9  135.0   42.0   \n",
       "2       2.0        2.0     2.0      2.0      2.0      2.0   0.7   96.0   32.0   \n",
       "3       2.0        2.0     2.0      2.0      2.0      2.0   0.7   46.0   52.0   \n",
       "4       2.0        2.0     2.0      2.0      2.0      2.0   1.0    NaN  200.0   \n",
       "\n",
       "   albu  protime  histology  \n",
       "0   4.0      NaN          1  \n",
       "1   3.5      NaN          1  \n",
       "2   4.0      NaN          1  \n",
       "3   4.0     80.0          1  \n",
       "4   4.0      NaN          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"target\",axis=1)\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'gender', 'steroid', 'antivirals', 'fatigue', 'malaise',\n",
      "       'anorexia', 'liverBig', 'liverFirm', 'spleen', 'spiders', 'ascites',\n",
      "       'varices', 'bili', 'alk', 'sgot', 'albu', 'protime', 'histology'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Split the data into X_train, X_test, y_train, y_test with test_size = 0.20 using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 19)\n",
      "(31, 19)\n",
      "(124,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "## Print the shape of X_train, X_test, y_train, y_test\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Check null values in train and test, check value_counts in y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            0\n",
      "gender         0\n",
      "steroid        0\n",
      "antivirals     0\n",
      "fatigue        1\n",
      "malaise        1\n",
      "anorexia       1\n",
      "liverBig       9\n",
      "liverFirm     10\n",
      "spleen         4\n",
      "spiders        4\n",
      "ascites        4\n",
      "varices        4\n",
      "bili           5\n",
      "alk           23\n",
      "sgot           4\n",
      "albu           9\n",
      "protime       54\n",
      "histology      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null values in train\n",
    "print(X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            0\n",
      "gender         0\n",
      "steroid        1\n",
      "antivirals     0\n",
      "fatigue        0\n",
      "malaise        0\n",
      "anorexia       0\n",
      "liverBig       1\n",
      "liverFirm      1\n",
      "spleen         1\n",
      "spiders        1\n",
      "ascites        1\n",
      "varices        1\n",
      "bili           1\n",
      "alk            6\n",
      "sgot           0\n",
      "albu           7\n",
      "protime       13\n",
      "histology      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null values in test\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    97\n",
      "1    27\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    26\n",
      "1     5\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Impute the Categorical Columns with mode and Numerical columns with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train = X_train[cat_cols]\n",
    "df_cat_test = X_test[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liverBig</th>\n",
       "      <th>liverFirm</th>\n",
       "      <th>spleen</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  steroid  antivirals  fatigue  malaise  anorexia  liverBig  \\\n",
       "0       1      2.0           2      1.0      2.0       2.0       2.0   \n",
       "\n",
       "   liverFirm  spleen  spiders  ascites  varices  histology  \n",
       "0        2.0     2.0      2.0      2.0      2.0          1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute on train\n",
    "df_cat_train = df_cat_train.fillna(df_cat_train.mode().iloc[0])\n",
    "\n",
    "# Impute on test\n",
    "df_cat_test = df_cat_test.fillna(df_cat_train.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_train = X_train[num_cols]\n",
    "df_num_test = X_test[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute on train\n",
    "df_num_train = df_num_train.fillna(df_num_train.mean())\n",
    "\n",
    "#Impute on test\n",
    "df_num_test = df_num_test.fillna(df_num_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numeric and categorical in train\n",
    "X_train = pd.concat([df_num_train, df_cat_train], axis = 1)\n",
    "\n",
    "# Combine numeric and categorical in test\n",
    "X_test = pd.concat([df_num_test, df_cat_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bili', 'alk', 'sgot', 'albu', 'protime', 'gender', 'steroid',\n",
       "       'antivirals', 'fatigue', 'malaise', 'anorexia', 'liverBig', 'liverFirm',\n",
       "       'spleen', 'spiders', 'ascites', 'varices', 'histology'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "bili          0\n",
       "alk           0\n",
       "sgot          0\n",
       "albu          0\n",
       "protime       0\n",
       "gender        0\n",
       "steroid       0\n",
       "antivirals    0\n",
       "fatigue       0\n",
       "malaise       0\n",
       "anorexia      0\n",
       "liverBig      0\n",
       "liverFirm     0\n",
       "spleen        0\n",
       "spiders       0\n",
       "ascites       0\n",
       "varices       0\n",
       "histology     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "bili          0\n",
       "alk           0\n",
       "sgot          0\n",
       "albu          0\n",
       "protime       0\n",
       "gender        0\n",
       "steroid       0\n",
       "antivirals    0\n",
       "fatigue       0\n",
       "malaise       0\n",
       "anorexia      0\n",
       "liverBig      0\n",
       "liverFirm     0\n",
       "spleen        0\n",
       "spiders       0\n",
       "ascites       0\n",
       "varices       0\n",
       "histology     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all the categorical columns to Integer Format before dummification (2.0 as 2 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train[cat_cols] = X_train[cat_cols].astype('int')\n",
    "\n",
    "# Test\n",
    "X_test[cat_cols] = X_test[cat_cols].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Dummify the Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical Columns to Dummies\n",
    "# Train\n",
    "X_train = pd.get_dummies(X_train, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Test\n",
    "X_test = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical Columns to Dummies\n",
    "\n",
    "#train_objs_num = len(X_train)\n",
    "#dataset = pd.concat(objs=[X_train, X_test], axis=0)\n",
    "\n",
    "#dataset_preprocessed = pd.get_dummies(dataset, columns=cat_cols,drop_first=True)\n",
    "\n",
    "#X_train = dataset_preprocessed[:train_objs_num]\n",
    "#X_test = dataset_preprocessed[train_objs_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bili', 'alk', 'sgot', 'albu', 'protime', 'gender_2',\n",
       "       'steroid_2', 'antivirals_2', 'fatigue_2', 'malaise_2', 'anorexia_2',\n",
       "       'liverBig_2', 'liverFirm_2', 'spleen_2', 'spiders_2', 'ascites_2',\n",
       "       'varices_2', 'histology_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bili', 'alk', 'sgot', 'albu', 'protime', 'gender_2',\n",
       "       'steroid_2', 'antivirals_2', 'fatigue_2', 'malaise_2', 'anorexia_2',\n",
       "       'liverBig_2', 'liverFirm_2', 'spleen_2', 'spiders_2', 'ascites_2',\n",
       "       'varices_2', 'histology_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Scale the numeric attributes [\"age\", \"bili\", \"alk\", \"sgot\", \"albu\", \"protime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_cols = [\"age\", \"bili\", \"alk\", \"sgot\", \"albu\", \"protime\"]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train.loc[:,num_cols])\n",
    "\n",
    "# scale on train\n",
    "X_train.loc[:,num_cols] = scaler.transform(X_train.loc[:,num_cols])\n",
    "\n",
    "# scale on test\n",
    "X_test.loc[:,num_cols] = scaler.transform(X_test.loc[:,num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL BUILDING\n",
    "\n",
    "    A. SVM\n",
    "    B. Random Forest\n",
    "    C. Stacking (With LR, DT, KNN)\n",
    "    D. Gradient Boosting (GBM)\n",
    "    E. XGBoost\n",
    "    F. Adaptive Boosting (AdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 ms, sys: 219 µs, total: 2.17 ms\n",
      "Wall time: 1.92 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit\n",
    "%time svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Conf Matrix : \n",
      " [[17 10]\n",
      " [ 1 96]]\n",
      "\n",
      "TRAIN DATA ACCURACY 0.9112903225806451\n",
      "\n",
      "Train data f1-score for class '1' 0.7555555555555556\n",
      "\n",
      "Train data f1-score for class '2' 0.9458128078817735\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST Conf Matrix : \n",
      " [[ 3  2]\n",
      " [ 1 25]]\n",
      "\n",
      "TEST DATA ACCURACY 0.9032258064516129\n",
      "\n",
      "Test data f1-score for class '1' 0.6666666666666665\n",
      "\n",
      "Test data f1-score for class '2' 0.9433962264150944\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = svc.predict(X_train)\n",
    "test_predictions = svc.predict(X_test)\n",
    "\n",
    "### Train data accuracy\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "print(\"TRAIN Conf Matrix : \\n\", confusion_matrix(y_train, train_predictions))\n",
    "print(\"\\nTRAIN DATA ACCURACY\",accuracy_score(y_train,train_predictions))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,train_predictions,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,train_predictions,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "\n",
    "print(\"TEST Conf Matrix : \\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"\\nTEST DATA ACCURACY\",accuracy_score(y_test,test_predictions))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,test_predictions,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,test_predictions,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with Grid Search for Paramater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Grid Search for parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_grid = SVC()\n",
    " \n",
    "\n",
    "param_grid = { \n",
    "                'C': [0.01, 0.1, 1, 10, 20, 50, 100],\n",
    "                'gamma': [0.01, 0.1, 1, 10, 100], \n",
    "                'kernel':['linear', 'rbf', 'poly', 'sigmoid']\n",
    "             }\n",
    "\n",
    " \n",
    "svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 10) # cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.6 s, sys: 4.85 ms, total: 7.61 s\n",
      "Wall time: 7.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 20, 50, 100], 'gamma': [0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit the grid search model\n",
    "%time svc_cv_grid.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "svc_cv_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9354838709677419\n",
      "\n",
      "Train data f1-score for class '1' 0.8333333333333334\n",
      "\n",
      "Train data f1-score for class '2' 0.9600000000000001\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.9032258064516129\n",
      "\n",
      "Test data f1-score for class '1' 0.5714285714285715\n",
      "\n",
      "Test data f1-score for class '2' 0.9454545454545454\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = svc_cv_grid.predict(X_train)\n",
    "test_predictions = svc_cv_grid.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,train_predictions))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,train_predictions,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,train_predictions,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,test_predictions))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,test_predictions,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,test_predictions,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 ms, sys: 0 ns, total: 24.1 ms\n",
      "Wall time: 23.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rfc.fit(X = X_train,y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 1.0\n",
      "\n",
      "Train data f1-score for class '1' 1.0\n",
      "\n",
      "Train data f1-score for class '2' 1.0\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8387096774193549\n",
      "\n",
      "Test data f1-score for class '1' 0.6153846153846154\n",
      "\n",
      "Test data f1-score for class '2' 0.8979591836734695\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = rfc.predict(X_train)\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,train_predictions))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,train_predictions,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,train_predictions,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,test_predictions))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,test_predictions,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,test_predictions,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features for Random Forest basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09629968, 0.1070079 , 0.10616956, 0.06338865, 0.20623034,\n",
       "       0.07984368, 0.00903009, 0.00592599, 0.00596591, 0.01888549,\n",
       "       0.03340111, 0.01161374, 0.0076192 , 0.03260604, 0.01069523,\n",
       "       0.07229486, 0.07248012, 0.0226687 , 0.0378737 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb8f03a2240>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get important Features\n",
    "feat_importances = pd.Series(rfc.feature_importances_, index = X_train.columns)\n",
    "feat_importances.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb8f02d02e8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances_ordered = feat_importances.nlargest(19)\n",
    "feat_importances_ordered.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "## n_jobs = -1 uses all cores of processor\n",
    "## max_features is the maximum number of attributes to select for each tree\n",
    "rfc_grid = RandomForestClassifier(n_jobs=-1, max_features='sqrt', class_weight='balanced_subsample')\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "## n_estimators is the number of trees in the forest\n",
    "## max_depth is how deep each tree can be\n",
    "## min_sample_leaf is the minimum samples required in each leaf node for the root node to split\n",
    "## \"A node will only be split if in each of it's leaf nodes there should be min_sample_leaf\"\n",
    "\n",
    "param_grid = {\"n_estimators\" : [10, 25, 50, 75, 100],\n",
    "           \"max_depth\" : [10, 12, 14, 16, 18, 20],\n",
    "           \"min_samples_leaf\" : [5, 10, 15, 20],\n",
    "           \"class_weight\" : ['balanced','balanced_subsample']}\n",
    " \n",
    "rfc_cv_grid = RandomizedSearchCV(estimator = rfc_grid, param_distributions = param_grid, cv = 3, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 673 ms, total: 4.97 s\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=None, max_features='sqrt',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [10, 25, 50, 75, 100], 'max_depth': [10, 12, 14, 16, 18, 20], 'min_samples_leaf': [5, 10, 15, 20], 'class_weight': ['balanced', 'balanced_subsample']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rfc_cv_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 75,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_depth': 18,\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv_grid.best_params_\n",
    "#rfc_cv_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.8951612903225806\n",
      "\n",
      "Train data f1-score for class '1' 0.7936507936507936\n",
      "\n",
      "Train data f1-score for class '2' 0.9297297297297297\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.7419354838709677\n",
      "\n",
      "Test data f1-score for class '1' 0.42857142857142855\n",
      "\n",
      "Test data f1-score for class '2' 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = rfc_cv_grid.predict(X_train)\n",
    "test_predictions = rfc_cv_grid.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,train_predictions))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,train_predictions,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,train_predictions,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,test_predictions))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,test_predictions,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,test_predictions,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features for Random Forest CV Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07678882, 0.1852945 , 0.06246728, 0.04216115, 0.17528999,\n",
       "       0.07030769, 0.00501819, 0.00426238, 0.00073033, 0.01909601,\n",
       "       0.04306269, 0.00618095, 0.00903007, 0.00738856, 0.0238428 ,\n",
       "       0.12096373, 0.05890658, 0.01711118, 0.07209711])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv_grid.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get important Features\n",
    "feat_importances = pd.Series(rfc_cv_grid.best_estimator_.feature_importances_, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb8f0213a58>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances_ordered = feat_importances.nlargest(11)\n",
    "feat_importances_ordered.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train_dtc = dtc.predict(X_train)\n",
    "y_pred_test_dtc = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression()\n",
    "\n",
    "lrc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train_lrc = lrc.predict(X_train)\n",
    "y_pred_test_lrc = lrc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_knn = knn.predict(X_train)\n",
    "y_pred_test_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take mode of the above predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = np.array([y_pred_train_dtc,y_pred_train_lrc,y_pred_train_knn]).T\n",
    "stacked_pred_train = mode(stack_train,axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_test = np.array([y_pred_test_dtc,y_pred_test_lrc,y_pred_test_knn]).T\n",
    "stacked_pred_test = mode(stack_test,axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = rfc_cv_grid.predict(X_train)\n",
    "test_predictions = rfc_cv_grid.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Build Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting is a type of boosting. \n",
    "\n",
    "The key idea behind gradient boosting is to set the target outcomes for this next model in order to minimize the error. The target outcome for each case in the data set depends on how much a change in that case’s prediction impacts the overall prediction error.\n",
    "\n",
    "If, for case X(i), a small change in the prediction causes a large drop in error, then the next target outcome is a high value. Predictions from the new model that are close to its targets will reduce the error.\n",
    "\n",
    "If, for case X(j), a small change in the prediction causes no change in error, then the next target outcome is zero because changing this prediction does not decrease the error.\n",
    "\n",
    "The name gradient boosting arises because of setting target outcomes based on the gradient of the error with respect to the prediction of each case. Each new model takes a step in the direction that minimizes prediction error, in the space of possible predictions for each training case.\n",
    "\n",
    "1. Initialize the outcome\n",
    "2. Iterate from 1 to total number of trees\n",
    "  <br>2.1 Update the weights for targets based on previous run (higher for the ones mis-classified)\n",
    "  <br>2.2 Fit the model on selected subsample of data\n",
    "  <br>2.3 Make predictions on the full set of observations\n",
    "  <br>2.4 Update the output with current results taking into account the learning rate\n",
    "3. Return the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important parameters are learning_rate, n_estimators and subsample\n",
    "- **learning_rate**\n",
    "    -  This determines the impact of each tree on the final outcome (step 2.4). GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates.\n",
    "    -  Lower values are generally preferred as they make the model robust to the specific characteristics of tree and thus allowing it to generalize well.\n",
    "    -  Lower values would require higher number of trees to model all the relations and will be computationally expensive.\n",
    "- **n_estimators**\n",
    "    -  The number of sequential trees to be modeled (step 2)\n",
    "    -  Though GBM is fairly robust at higher number of trees but it can still overfit at a point. Hence, this should be tuned using CV for a particular learning rate.\n",
    "- **subsample**\n",
    "    -  The fraction of observations to be selected for each tree. Selection is done by random sampling.\n",
    "    -  Values slightly less than 1 make the model robust by reducing the variance.\n",
    "    -  Typical values ~0.8 generally work fine but can be fine-tuned further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model = GradientBoostingClassifier(n_estimators=50,\n",
    "                                       learning_rate=0.3,\n",
    "                                       subsample=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Gradient Boosting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.7 ms, sys: 0 ns, total: 54.7 ms\n",
      "Wall time: 53.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=0.8, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time GBM_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = GBM_model.predict(X_train)\n",
    "test_predictions = GBM_model.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Cross validation for GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model in use\n",
    "GBM = GradientBoostingClassifier() \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [100,150,200,250],\n",
    "           \"max_depth\" : [5, 10],\n",
    "           \"learning_rate\" : [0.1,0.5,0.9]}\n",
    " \n",
    "CV_GBM = GridSearchCV(estimator=GBM, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.28 s, sys: 0 ns, total: 3.28 s\n",
      "Wall time: 3.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 150, 200, 250], 'max_depth': [5, 10], 'learning_rate': [0.1, 0.5, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time CV_GBM.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.77419, std: 0.02176, params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100},\n",
       " mean: 0.77419, std: 0.02176, params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150},\n",
       " mean: 0.77419, std: 0.02176, params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200},\n",
       " mean: 0.77419, std: 0.03098, params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       " mean: 0.75806, std: 0.06515, params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 150},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 250},\n",
       " mean: 0.79032, std: 0.01049, params: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 100},\n",
       " mean: 0.78226, std: 0.03564, params: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 150},\n",
       " mean: 0.79839, std: 0.02785, params: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 200},\n",
       " mean: 0.79839, std: 0.02785, params: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 250},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 100},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 150},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 200},\n",
       " mean: 0.75806, std: 0.06813, params: {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 250},\n",
       " mean: 0.79839, std: 0.00903, params: {'learning_rate': 0.9, 'max_depth': 5, 'n_estimators': 100},\n",
       " mean: 0.78226, std: 0.01760, params: {'learning_rate': 0.9, 'max_depth': 5, 'n_estimators': 150},\n",
       " mean: 0.79839, std: 0.01273, params: {'learning_rate': 0.9, 'max_depth': 5, 'n_estimators': 200},\n",
       " mean: 0.78226, std: 0.03148, params: {'learning_rate': 0.9, 'max_depth': 5, 'n_estimators': 250},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.9, 'max_depth': 10, 'n_estimators': 100},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.9, 'max_depth': 10, 'n_estimators': 150},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.9, 'max_depth': 10, 'n_estimators': 200},\n",
       " mean: 0.75000, std: 0.06023, params: {'learning_rate': 0.9, 'max_depth': 10, 'n_estimators': 250}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best parameters set and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983870967741935 {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_gbm_model = CV_GBM.best_estimator_\n",
    "print (CV_GBM.best_score_, CV_GBM.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = CV_GBM.predict(X_train)\n",
    "test_predictions = CV_GBM.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Build XGBOOST Classifier\n",
    "XGBoost (eXtreme Gradient Boosting) is an advanced implementation of gradient boosting algorithm.\n",
    "#### The XGBoost Advantage\n",
    "-  Regularization:\n",
    "    -  Standard GBM implementation has no regularization like XGBoost, therefore it also helps to reduce overfitting.\n",
    "    -  In fact, XGBoost is also known as ‘regularized boosting‘ technique.\n",
    "-  Parallel Processing:\n",
    "    -  XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "    -  Boosting is sequential process that each tree can be built only after the previous one, and it  can be parallelized with making a tree using all cores. Refer. http://zhanpengfang.github.io/418home.html\n",
    "    \n",
    "    -  XGBoost also supports implementation on Hadoop.\n",
    "-  High Flexibility\n",
    "    -  XGBoost allow users to define custom optimization objectives and evaluation criteria.\n",
    "    -  This adds a whole new dimension to the model and there is no limit to what we can do.\n",
    "-  Handling Missing Values\n",
    "    -  XGBoost has an in-built routine to handle missing values.\n",
    "    -  User is required to supply a different value than other observations and pass that as a parameter. XGBoost tries different things as it encounters a missing value on each node and learns which path to take for missing values in future.\n",
    "-  Tree Pruning:\n",
    "    -  A GBM would stop splitting a node when it encounters a negative loss in the split. Thus it is more of a greedy algorithm.\n",
    "    -  XGBoost on the other hand make splits upto the max_depth specified and then start pruning the tree backwards and remove splits beyond which there is no positive gain.\n",
    "    -  Another advantage is that sometimes a split of negative loss say -2 may be followed by a split of positive loss +10. GBM would stop as it encounters -2. But XGBoost will go deeper and it will see a combined effect of +8 of the split and keep both.\n",
    "-  Built-in Cross-Validation\n",
    "    -  XGBoost allows user to run a cross-validation at each iteration of the boosting process and thus it is easy to get the exact optimum number of boosting iterations in a single run.\n",
    "    -  This is unlike GBM where we have to run a grid-search and only a limited values can be tested.\n",
    "-  Continue on Existing Model\n",
    "    -  User can start training an XGBoost model from its last iteration of previous run. This can be of significant advantage in certain specific applications.\n",
    "    -  GBM implementation of sklearn also has this feature so they are even on this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create XGBoost Classifier\n",
    "\n",
    "There are different hyperparameters that we can tune and the parametres are different from baselearner to baselearner. \n",
    "<br>In tree based learners, which are the most common ones in xgboost applications, the following are the most commonly tuned hyperparameters:\n",
    "\n",
    "-  **learning rate/eta:** governs how quickly the model fits the residual error using additional base learners. If it is a smaller learning rate, it will need more boosting rounds, hence more time, to achieve the same reduction in residual error as one with larger learning rate. Typically, it lies between 0.01 – 0.3\n",
    "-  **max_depth:** max depth per tree. This controls how deep our tree can grow. The Larger the depth, more complex the model will be and higher chances of overfitting. Larger data sets require deep trees to learn the rules from data. Default = 6.\n",
    "-  **subsample:** % samples used per tree. This is the fraction of the total training set that can be used in any boosting round. Low value may lead to underfitting issues. A very high value can cause over-fitting problems.\n",
    "-  **colsample_bytree:** % features used per tree. This is the fraction of the number of columns that we can use in any boosting round. A smaller value is an additional regularization and a larger value may be cause overfitting issues.\n",
    "-  **n_estimators:** number of estimators (base learners). This is the number of boosting rounds.\n",
    "<br><br>The three hyperparameters below are regularization hyperparameters.\n",
    "-  **gamma:** min loss reduction to create new tree split. default = 0 means no regularization.\n",
    "-  **lambda:** L2 reg on leaf weights. Equivalent to Ridge regression.\n",
    "-  **alpha:** L1 reg on leaf weights. Equivalent to Lasso regression.\n",
    "\n",
    "\n",
    "Refer: https://xgboost.readthedocs.io/en/latest/python/python_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the Xgboost module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGB_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 ms, sys: 4.15 ms, total: 42.2 ms\n",
      "Wall time: 41.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = XGB_model.predict(X_train)\n",
    "test_predictions = XGB_model.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Cross validation for XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(n_jobs=-1)\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\n",
    "     'colsample_bytree': np.linspace(0.5, 0.9, 5),\n",
    "     'n_estimators':[100, 200],\n",
    "     'max_depth': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    " \n",
    "CV_XGB = GridSearchCV(estimator=XGB, param_grid=param_grid, cv= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 250 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'colsample_bytree': array([0.5, 0.6, 0.7, 0.8, 0.9]), 'n_estimators': [100, 200], 'max_depth': [10, 15, 20, 25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time CV_XGB.fit(X = X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best parameters set and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145161290322581 {'colsample_bytree': 0.6, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_xgb_model = CV_XGB.best_estimator_\n",
    "print (CV_XGB.best_score_, CV_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = CV_XGB.predict(X_train)\n",
    "test_predictions = CV_XGB.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Adapative Boosting (AdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It combines multiple classifiers to increase the accuracy of classifiers. AdaBoost is an iterative ensemble method. AdaBoost classifier builds a strong classifier by combining multiple poorly performing classifiers so that you will get high accuracy strong classifier. The basic concept behind Adaboost is to set the weights of classifiers and training the data sample in each iteration such that it ensures the accurate predictions of unusual observations. Any machine learning algorithm can be used as base classifier if it accepts weights on the training set. Adaboost should meet two conditions:\n",
    "\n",
    "The classifier should be trained interactively on various weighed training examples.\n",
    "In each iteration, it tries to provide an excellent fit for these examples by minimizing training error.\n",
    "How does the AdaBoost algorithm work?\n",
    "\n",
    "It works in the following steps:\n",
    "1. Initially, Adaboost selects a training subset randomly.\n",
    "2. It iteratively trains the AdaBoost machine learning model by selecting the training set based on the accurate prediction of the last training.\n",
    "3. It assigns the higher weight to wrong classified observations so that in the next iteration these observations will get the high probability for classification.\n",
    "4. Also, It assigns the weight to the trained classifier in each iteration according to the accuracy of the classifier. The more accurate classifier will get high weight.\n",
    "5. This process iterate until the complete training data fits without any error or until reached to the specified maximum number of estimators.\n",
    "6. To classify, perform a \"vote\" across all of the learning algorithms you built.\n",
    "\n",
    "Reference: https://www.datacamp.com/community/tutorials/adaboost-classifier-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.3 ms, sys: 7.78 ms, total: 81.1 ms\n",
      "Wall time: 80.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = adaboost.predict(X_train)\n",
    "test_predictions = adaboost.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Cross validation for XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\n",
    "     'n_estimators':[100, 200],\n",
    "     'learning_rate': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    " \n",
    "CV_ada = GridSearchCV(estimator=adaboost, param_grid=param_grid, cv= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 3.24 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time CV_ada.fit(X = X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best parameters set and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8629032258064516 {'learning_rate': 0.1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "print (CV_ada.best_score_, CV_ada.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA ACCURACY 0.9274193548387096\n",
      "\n",
      "Train data f1-score for class '1' 0.8163265306122449\n",
      "\n",
      "Train data f1-score for class '2' 0.9547738693467337\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "TEST DATA ACCURACY 0.8709677419354839\n",
      "\n",
      "Test data f1-score for class '1' 0.5\n",
      "\n",
      "Test data f1-score for class '2' 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "train_predictions = CV_ada.predict(X_train)\n",
    "test_predictions = CV_ada.predict(X_test)\n",
    "\n",
    "print(\"TRAIN DATA ACCURACY\",accuracy_score(y_train,stacked_pred_train))\n",
    "print(\"\\nTrain data f1-score for class '1'\",f1_score(y_train,stacked_pred_train,pos_label=1))\n",
    "print(\"\\nTrain data f1-score for class '2'\",f1_score(y_train,stacked_pred_train,pos_label=2))\n",
    "\n",
    "### Test data accuracy\n",
    "print(\"\\n\\n--------------------------------------\\n\\n\")\n",
    "print(\"TEST DATA ACCURACY\",accuracy_score(y_test,stacked_pred_test))\n",
    "print(\"\\nTest data f1-score for class '1'\",f1_score(y_test,stacked_pred_test,pos_label=1))\n",
    "print(\"\\nTest data f1-score for class '2'\",f1_score(y_test,stacked_pred_test,pos_label=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
